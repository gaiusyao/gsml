{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深入了解机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;蟋蟀在较为炎热的天气里鸣叫更为频繁，下图描述了蟋蟀每分钟鸣叫声和温度的关系：\n",
    "\n",
    "![图 1. 每分钟的鸣叫声与温度（摄氏度）的关系](http://oxv2o8wp9.bkt.clouddn.com/01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;毫无疑问，此曲线图表明温度随着鸣叫声次数的增加而上升。鸣叫声与温度之间的关系是线性关系吗？是的，可以绘制一条直线来近似地表示这种关系，如下所示：\n",
    "\n",
    "![图2.线性关系](http://oxv2o8wp9.bkt.clouddn.com/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练与损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;简单来说，**训练**模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为**经验风险最小化**。\n",
    "\n",
    "&emsp;&emsp;损失是对糟糕预测的惩罚。也就是说，**损失**是一个数值，表示对于单个样本而言模型预测的准确程度。如果模型的预测完全准确，则损失为零，否则损失会较大。训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。例如，下图左侧显示的是损失较大的模型，右侧显示的是损失较小的模型。关于此图，请注意以下几点：\n",
    "\n",
    "- 红色箭头表示损失。\n",
    "- 蓝线表示预测。\n",
    "\n",
    "![图 3. 左侧模型的损失较大；右侧模型的损失较小](http://oxv2o8wp9.bkt.clouddn.com/03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;请注意，左侧曲线图中的红色箭头比右侧曲线图中的对应红色箭头长得多。显然，相较于左侧曲线图中的蓝线，右侧曲线图中的蓝线代表的是预测效果更好的模型。\n",
    "\n",
    "&emsp;&emsp;你可能想知道自己能否创建一个数学函数（损失函数），以有意义的方式汇总各个损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平方损失：一种常见的损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们要看的线性回归模型使用的是一种称为**平方损失**（又称为 **L2 损失**）的损失函数。单个样本的平方损失如下：\n",
    "```\n",
    "  = the square of the difference between the label and the prediction\n",
    "  = (observation - prediction(x))2\n",
    "  = (y - y')2\n",
    "```\n",
    "&emsp;&emsp;均方误差 (MSE) 指的是每个样本的平均平方损失。要计算 MSE，请求出各个样本的所有平方损失之和，然后除以样本数量：\n",
    "\n",
    "> $MSE = \\frac{1}{N} \\sum_{(x,y)\\in D} (y - prediction(x))^2$\n",
    "\n",
    "&emsp;&emsp;其中：\n",
    "\n",
    "- $(x, y)$ 指的是样本，其中\n",
    "    - $x$ 指的是模型进行预测时使用的特征集（例如，温度、年龄和交配成功率）。\n",
    "    - $y$ 指的是样本的标签（例如，每分钟的鸣叫次数）。\n",
    "- $prediction(x)$ 指的是权重和偏差与特征集 $x$ 结合的函数。\n",
    "- $D$ 指的是包含多个有标签样本（即$(x, y)$ ）的数据集。\n",
    "- $N$ 指的是 $D$ 中的样本数量。\n",
    " \n",
    "&emsp;&emsp;虽然 MSE 常用于机器学习，但它既不是唯一实用的损失函数，也不是适用于所有情形的最佳损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查理解情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 均分误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://developers.google.cn/machine-learning/crash-course/images/MCEDescendingIntoMLLeft.png)\n",
    "\n",
    "&emsp;&emsp;对于以上曲线图中显示的两个数据集，哪个数据集的均方误差 (MSE) 较高？\n",
    "- [ ] 左侧的数据集。\n",
    "- [x] 右侧的数据集。\n",
    "\n",
    "> 线上的 8 个样本产生的总损失为 0。不过，尽管只有两个点在线外，但这两个点的离线距离依然是左图中离群点的 2 倍。平方损失进一步加大差异，因此两个点的偏移量产生的损失是一个点的 4 倍。\n",
    "\n",
    "> $MSE = \\frac{0^2 + 0^2 + 0^2 + 2^2 + 0^2 + 0^2 + 0^2 + 2^2 + 0^2 +0^2} {10} = 0.8$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
